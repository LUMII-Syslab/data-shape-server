# Getting Started

## Initial setup for the database

- Obtain the Schema Server database initialization script from [here](sql/public.pgsql). This dump already contains the schema `public` which serves as a schema register for this database.

- Choose the name for your database, e.g., `dss` and create the database.

```
createdb dss
```

- create the role `rdf` which will own the db objects

- load the public schema executing the command:

```
psql dss < public.pgsql
```

## Obtain the data to be imported

- obtain a JSON file containing the shape info extracted from the endpoint (see [OBIS-SchemaExtractor](https://github.com/LUMII-Syslab/OBIS-SchemaExtractor)).

## Import the first schema

The data shape import service has the following prerequisites:

- Access to the [Data Shape Server (DSS)](https://github.com/LUMII-Syslab/data-shape-server) database, containing:
  - an initialized schema registry (usually in the DB schema `public`)
  - an empty schema template as the DB schema `empty`



- Obtain the Schema Server schema template from [here](sql/empty_template.pgsql).

- Choose the name for your schema, e.g., `myendpoint`.

- Execute the following commands:

```
psql dss < empty_template.pgsql
psql -c "alter schema empty rename to myendpoint" dss
```

You can repeat these commands if you need to import another schema,

- create an environment file (copy `sample.env` to `.env`) and configure the following variables inside the `.env` file:
  - `DB_URL` – connection string to the Data Shape Server PostgreSQL database,
  - `DB_SCHEMA` – name of the db schema (e.g., `myendpoint`) where the shapes should be imported into
  - `INPUT_FILE` – name of the JSON file with the extracted information (see previous section).
  - `SCHEMA_NAME` – profile for UI organization; use the same string, as for `DB_SCHEMA`, if not instructed otherwise
  - `SCHEMA_DISPLAY_NAME` – schema name for the UI (appears in a dropdown list of available schemas)
  - `SPARQL_URL` – URL for the SPARQL requests to the endpoint
  - `NAMED_GRAPH` – named graph (optional)
  - `PUBLIC_URL` – public web site for the endpoint (optional)
  - 
  - `REGISTRY_SCHEMA` – name of the DB schema which stores the schemate registry (optional, defaults to `public`)
  - `OVERRIDE_DB_SCHEMA` – name of the DB schema which stores the schemate registry (optional, defaults to `public`)

- ensure that `node.js` version ≥ 16 is installed

- run `npm install` from the command line to install the prerequisites

- run `node work.js` from the command line to start the import

## Meta-parameters for environment tuning

The schema import shall set the basic options for meta-parameters in the schema `public`, tables `endpoints`, `schemata`, `schemata_to_endpoints` and `tree_profiles` (the `display_name` field in `schemata_to_endpoints` table allows to locate the information related to the performed import).

To repeat import of a schema with the same display name, change the value of the already existing display name, or delete previous row of `schemata_to_endpoints`, as well as the matching rows in tables `endpoints` and `schemata`.

## Namespace table prepopulation and tuning

If desired, the namespaces table `ns` can also be prepopulated before the import (there is a default pre-population done by the empty schema creation script).

For any prefixes encountered in input JSON, an existing `ns` entry will be used, if possible.

For missing `ns` entries, the prefix.cc API will be queried to get the short form of the prefix.

Still unknown prefixes will get autogenerated short forms like `auto_42`.

The namespaces table can be edited manually after the import. Change the prefixes to the ones you would like to see in the user interface. 

Setting a default namespace would simplify its entity appearance. 

Setting priorities to namespaces will order the entities in code completion lists. 

## Acknowledgements

Supported in part by Latvian Science Council project lzp-2021/1-0389 "Visual Queries in Distributed Knowledge Graphs" (since 2022).
