# Getting Started

## Initial setup for the database

- Obtain the Schema Server database initialization script from [here](sql/public.pgsql). This dump already contains the schema `public` which serves as a schema register for this database.

- Choose the name for your database, e.g., `dss`.

- Execute the following commands:

```
createdb dss
psql dss < public.pgsql
```

## Obtain the data to be imported

- obtain a JSON file containing the shape info extracted from the endpoint (see [OBIS-SchemaExtractor](https://github.com/LUMII-Syslab/OBIS-SchemaExtractor)).

## Import the first schema

- Obtain the Schema Server schema template from [here](sql/empty_template.pgsql).

- Choose the name for your schema, e.g., `myendpoint`.

- Execute the following commands:

```
psql dss < _template.pgsql
psql -c "alter schema empty rename to myendpoint" dss
```

You can repeat these commands if you need to import another schema,

- create an environment file (copy `sample.env` to `.env`) and configure the following variables inside the `.env` file:
  - `DB_URL` – connection string to the Data Shape Server PostgreSQL database,
  - `DB_SCHEMA` – name of the db schema (e.g., `myendpoint`) where the shapes should be imported into
  - `INPUT_FILE` – name of the JSON file with the extracted information (see previous section).
  - `SCHEMA_NAME` – profile for UI organization; use the same string, as for `DB_SCHEMA`, if not instructed otherwise
  - `SCHEMA_DISPLAY_NAME` – schema name for the UI (appears in a dropdown list of available schemas)
  - `SPARQL_URL` – URL for the SPARQL requests to the endpoint
  - `NAMED_GRAPH` – named graph (optional)
  - `PUBLIC_URL` – public web site for the endpoint (optional)

- ensure that `node.js` is installed

- run `npm install` from the command line to install the prerequisites

- run `node work.js` from the command line to start the import

## Meta-parameters for environment tuning

The schema import shall set the basic options for meta-parameters in the schema `public` 
tables `endpoints`, `schemata`, `schemata_to_endpoints` and `tree_profiles` (the `display_name` field
in `schemata_to_endpoints` table allows to locate the information related to the performed import).

To repeat import of a schema with the same display name, change the value of the already existing display name, or 
delete previous row of `schemata_to_endpoints`, as well as the matching rows in tables `endpoints` and `schemata`.

## Namespace table prepopulation and tuning

If desired, the namespaces table `ns` can also be prepopulated before the import (there is a default pre-population done by the empty schema creation script).

For any prefixes encountered in input JSON, an existing `ns` entry will be used, if possible.

For missing `ns` entries, the prefix.cc API will be queried to get the short form of the prefix.

Still unknown prefixes will get autogenerated short forms like `auto_42`.

The namespaces table can be edited manually after the import. Change the prefixes to the ones you would like to see in the user interface. 
Setting a default namespace would simplify its entity appearance. 
Setting priorities to namespaces will order the entities in code completion lists. 

## Acknowledgements

Supported in part by Latvian Science Council project lzp-2021/1-0389 "Visual Queries in Distributed Knowledge Graphs" (since 2022).
